{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yGm6gQ79r1fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn nltk python-Levenshtein spacy&> /dev/null"
      ],
      "metadata": {
        "id": "_RW3uUgir2BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "nltk.download('punkt')\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "-QNRfNPxr2Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d7MJ3pzisK1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity"
      ],
      "metadata": {
        "id": "pWArXm-xsPCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard Similarity"
      ],
      "metadata": {
        "id": "2irBtl1gsRwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-bD8PoqBsM8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ycBjEZWsNCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levenshtein Distance"
      ],
      "metadata": {
        "id": "9t3dqjrVsT2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difflib Sequence Matching"
      ],
      "metadata": {
        "id": "RQDiIkozsVEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Copyscape"
      ],
      "metadata": {
        "id": "wk2zJgo0rzY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copyscape API credentials\n",
        "USERNAME = 'your_username'\n",
        "API_KEY = 'your_api_key'\n"
      ],
      "metadata": {
        "id": "TYlVnNVBryJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IGFomnEJv17"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Copyscape API URL\n",
        "COPESCAPE_API_URL = 'https://www.copyscape.com/api/'\n",
        "\n",
        "def copyscape_url_search(url, full_comparisons=0, ignore_sites=None, spend_limit=None):\n",
        "    \"\"\"\n",
        "    Perform a URL search using the Copyscape API.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'u': USERNAME,\n",
        "        'k': API_KEY,\n",
        "        'o': 'csearch',\n",
        "        'q': url,\n",
        "        'c': full_comparisons,\n",
        "        'f': 'json'\n",
        "    }\n",
        "\n",
        "    if ignore_sites:\n",
        "        params['i'] = ','.join(ignore_sites)\n",
        "\n",
        "    if spend_limit:\n",
        "        params['l'] = spend_limit\n",
        "\n",
        "    response = requests.get(COPESCAPE_API_URL, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def copyscape_text_search(text, full_comparisons=0, ignore_sites=None, spend_limit=None):\n",
        "    \"\"\"\n",
        "    Perform a text search using the Copyscape API.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'u': USERNAME,\n",
        "        'k': API_KEY,\n",
        "        'o': 'csearch',\n",
        "        'e': 'UTF-8',\n",
        "        'c': full_comparisons,\n",
        "        'f': 'json'\n",
        "    }\n",
        "\n",
        "    if ignore_sites:\n",
        "        params['i'] = ','.join(ignore_sites)\n",
        "\n",
        "    if spend_limit:\n",
        "        params['l'] = spend_limit\n",
        "\n",
        "    response = requests.post(COPESCAPE_API_URL, params=params, data=text.encode('utf-8'))\n",
        "    return response.json()\n",
        "\n",
        "def add_to_private_index(url=None, text=None, article_id=None, article_title=None):\n",
        "    \"\"\"\n",
        "    Add content to your private index using the Copyscape API.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'u': USERNAME,\n",
        "        'k': API_KEY,\n",
        "        'o': 'pindexadd',\n",
        "        'f': 'json'\n",
        "    }\n",
        "\n",
        "    if url:\n",
        "        params['q'] = url\n",
        "    elif text:\n",
        "        params['t'] = text\n",
        "        params['e'] = 'UTF-8'\n",
        "\n",
        "    if article_id:\n",
        "        params['i'] = article_id\n",
        "\n",
        "    if article_title:\n",
        "        params['a'] = article_title\n",
        "\n",
        "    if url:\n",
        "        response = requests.get(COPESCAPE_API_URL, params=params)\n",
        "    else:\n",
        "        response = requests.post(COPESCAPE_API_URL, params=params, data=text.encode('utf-8'))\n",
        "\n",
        "    return response.json()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # URL search example\n",
        "    url_search_result = copyscape_url_search('http://example.com')\n",
        "    print(url_search_result)\n",
        "\n",
        "    # Text search example\n",
        "    text_search_result = copyscape_text_search('This is a sample text to check for plagiarism.')\n",
        "    print(text_search_result)\n",
        "\n",
        "    # Add to private index example\n",
        "    add_result = add_to_private_index(text='This is a sample text to add to my private index.')\n",
        "    print(add_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from difflib import SequenceMatcher\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Function to calculate Levenshtein Distance\n",
        "def levenshtein_distance(s1: str, s2: str) -> int:\n",
        "    if len(s1) < len(s2):\n",
        "        return levenshtein_distance(s2, s1)\n",
        "\n",
        "    if len(s2) == 0:\n",
        "        return len(s1)\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "        previous_row = current_row\n",
        "\n",
        "    return previous_row[-1]\n",
        "\n",
        "# Function to calculate Sequence Matching\n",
        "def sequence_match_score(s1: str, s2: str) -> float:\n",
        "    return SequenceMatcher(None, s1, s2).ratio()\n",
        "\n",
        "# Function to calculate Jaccard Similarity\n",
        "def jaccard_similarity(s1: str, s2: str) -> float:\n",
        "    set1 = set(s1.split())\n",
        "    set2 = set(s2.split())\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "# Function to calculate Cosine Similarity\n",
        "def calculate_cosine_similarity(documents: List[str]) -> float:\n",
        "    count_vectorizer = CountVectorizer().fit_transform(documents)\n",
        "    vectors = count_vectorizer.toarray()\n",
        "    return cosine_similarity(vectors)[0][1]\n",
        "\n",
        "# Function to compare a document against multiple potential sources\n",
        "def compare_documents(suspected_text: str, source_texts: List[str]) -> List[Tuple[str, float, float, float, float]]:\n",
        "    results = []\n",
        "    for source_text in source_texts:\n",
        "        leven_distance = levenshtein_distance(suspected_text, source_text)\n",
        "        seq_match = sequence_match_score(suspected_text, source_text)\n",
        "        jaccard_sim = jaccard_similarity(suspected_text, source_text)\n",
        "        cosine_sim = calculate_cosine_similarity([suspected_text, source_text])\n",
        "        results.append((source_text, leven_distance, seq_match, jaccard_sim, cosine_sim))\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "suspected_text = \"This is a sample text that might be plagiarized.\"\n",
        "source_texts = [\n",
        "    \"This is a sample text that could be plagiarized.\",\n",
        "    \"An original text that has nothing to do with the suspected text.\",\n",
        "    \"This is another text that might be slightly similar to the suspected text.\",\n",
        "]\n",
        "\n",
        "# Compare the suspected document against the source documents\n",
        "comparison_results = compare_documents(suspected_text, source_texts)\n",
        "\n",
        "comparison_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmVy2tZtA32-",
        "outputId": "5781b19c-6655-4088-c6da-1651181cd532"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This is a sample text that could be plagiarized.',\n",
              "  5,\n",
              "  0.8958333333333334,\n",
              "  0.8,\n",
              "  0.8749999999999999),\n",
              " ('An original text that has nothing to do with the suspected text.',\n",
              "  47,\n",
              "  0.44642857142857145,\n",
              "  0.10526315789473684,\n",
              "  0.2834733547569204),\n",
              " ('This is another text that might be slightly similar to the suspected text.',\n",
              "  38,\n",
              "  0.5901639344262295,\n",
              "  0.375,\n",
              "  0.6390096504226936)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Integration with the existing comparison code\n",
        "def plagiarism_check_with_copyscape(suspected_text: str, source_texts: List[str], username: str, api_key: str):\n",
        "    # Perform the initial comparisons using local methods\n",
        "    local_comparisons = compare_documents(suspected_text, source_texts)\n",
        "\n",
        "    # Then, for each source text, perform a Copyscape text search.\n",
        "    # Here we mock the response as we can't make actual API calls.\n",
        "    copyscape_results = []\n",
        "    for source_text in source_texts:\n",
        "        # This would be an actual API call:\n",
        "        result = copyscape_text_search(source_text, username=username, api_key=api_key)\n",
        "\n",
        "\n",
        "        copyscape_results = process_copyscape_response(result)\n",
        "        copyscape_results.append(result)\n",
        "\n",
        "    # Combine local comparison results with Copyscape results\n",
        "    combined_results = []\n",
        "    for i, (source_text, leven_distance, seq_match, jaccard_sim, cosine_sim) in enumerate(local_comparisons):\n",
        "        copyscape_plagiarism_detected = copyscape_results[i][\"plagiarism_detected\"]\n",
        "        combined_results.append({\n",
        "            \"source_text\": source_text,\n",
        "            \"levenshtein_distance\": leven_distance,\n",
        "            \"sequence_match_score\": seq_match,\n",
        "            \"jaccard_similarity\": jaccard_sim,\n",
        "            \"cosine_similarity\": cosine_sim,\n",
        "            \"copyscape_plagiarism_detected\": copyscape_plagiarism_detected\n",
        "        })\n",
        "\n",
        "    return combined_results\n",
        "\n",
        "\n",
        "def process_copyscape_response(response_json):\n",
        "    results = []\n",
        "    for result in response_json.get('result', []):\n",
        "        copyscape_data = {\n",
        "            'index': result.get('index'),\n",
        "            'url': result.get('url'),\n",
        "            'title': result.get('title'),\n",
        "            'textsnippet': result.get('textsnippet'),\n",
        "            'minwordsmatched': result.get('minwordsmatched'),\n",
        "        }\n",
        "        if 'wordsmatched' in result:\n",
        "            copyscape_data.update({\n",
        "                'wordsmatched': result.get('wordsmatched'),\n",
        "                'percentmatched': result.get('percentmatched'),\n",
        "                'textmatched': result.get('textmatched'),\n",
        "            })\n",
        "        results.append(copyscape_data)\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage with mocked responses\n",
        "USERNAME = \"\"\n",
        "API_KEY = \"\"\n",
        "\n",
        "plagiarism_results = plagiarism_check_with_copyscape(suspected_text, source_texts, USERNAME, API_KEY)\n",
        "plagiarism_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "uHelty_rCCZt",
        "outputId": "e4abab8d-0f75-4f12-cd12-b27db6b384b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-37e866ffd9e8>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mplagiarism_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplagiarism_check_with_copyscape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuspected_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSERNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mplagiarism_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-37e866ffd9e8>\u001b[0m in \u001b[0;36mplagiarism_check_with_copyscape\u001b[0;34m(suspected_text, source_texts, username, api_key)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msource_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# This would be an actual API call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopyscape_text_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'copyscape_text_search' is not defined"
          ]
        }
      ]
    }
  ]
}
